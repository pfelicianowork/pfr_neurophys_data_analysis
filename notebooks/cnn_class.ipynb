{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SWR CNN Autoencoder & Classification Pipeline\n",
    "\n",
    "This notebook runs the complete SWR classification pipeline by importing and executing the main functions from the scripts in the `../cnn_autoencoder` directory.\n",
    "\n",
    "**Workflow:**\n",
    "1.  **Setup Paths:** Configure paths and set the main recording directory for inputs/outputs.\n",
    "2.  **Step 1:** Generate spectrograms and extract biological features.\n",
    "3.  **Step 2:** Train the CNN autoencoder (ResNet or VAE) on the spectrograms.\n",
    "4.  **Step 3:** Cluster events using a combination of autoencoder and biological features.\n",
    "5.  **Step 4:** Evaluate and visualize the final clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# --- 1. DEFINE PATHS & PARAMETERS ---\n",
    "\n",
    "# !! IMPORTANT: This is the user-specified path for all outputs (and inputs)\n",
    "recording_path = r\"F:\\Spikeinterface_practice\\s4_rec\"\n",
    "\n",
    "# This is the root of the project (pfr_neurophys_data_analysis)\n",
    "# Assumes this notebook is in pfr_neurophys_data_analysis/notebooks/\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "\n",
    "# Add the project root to the Python path to allow imports from cnn_autoencoder\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "# Change the current working directory to the recording path\n",
    "# All generated files (models, plots, .pkl) will be saved here.\n",
    "try:\n",
    "    os.chdir(recording_path)\n",
    "    print(f\"Changed working directory to: {os.getcwd()}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"ERROR: Recording path not found: {recording_path}\")\n",
    "    print(\"Please update the 'recording_path' variable in this cell.\")\n",
    "\n",
    "print(f\"Project root added to sys.path: {project_root}\")\n",
    "\n",
    "# --- 2. DEFINE PIPELINE PARAMETERS ---\n",
    "# These can be adjusted as needed\n",
    "ARCH = 'resnet'      # 'resnet', 'vae', or 'attention'\n",
    "LATENT_DIM = 128     # Latent dimension for the autoencoder\n",
    "EPOCHS = 15          # Number of epochs for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e337d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import your existing modules\n",
    "from open_ephys_loader import fast_openephys_dat_lfp\n",
    "from spike_analysis import SpikeAnalysis, loader, process_spike_data, load_processed_spike_data\n",
    "from swr_detection.swr_hmm_detection import SWRHMMParams, SWRHMMDetector\n",
    "from swr_detection.pipeline import find_region_channels, build_region_lfp\n",
    "from swr_detection.swr_spectral_features import batch_compute_spectral_features\n",
    "\n",
    "# Import new feature extraction module\n",
    "from feature_extraction import batch_extract_features, validate_biological_features\n",
    "\"\"\"\n",
    "Performs SWR detection, computes spectrograms, AND extracts biological features.\n",
    "This creates a richer dataset for clustering.\n",
    "\"\"\"\n",
    "print(\"=\"*80)\n",
    "print(\"IMPROVED SWR DETECTION WITH COMPREHENSIVE FEATURE EXTRACTION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# --- Configuration ---\n",
    "dat_path = r\"D:\\Spikeinterface_practice\\s4_rec\\ephys.dat\"\n",
    "num_channels = 43\n",
    "selected_channels = {\n",
    "    'CA1_tet1': 17, 'CA1_tet2': 21, 'RTC_tet1': 14, 'PFC_tet1': 0, 'PFC_tet2': 5\n",
    "}\n",
    "fs_in = 30000.0\n",
    "fs_out = 1000.0\n",
    "output_dir = \"all_spectrograms\"\n",
    "\n",
    "# --- Load LFP and Spike Data ---\n",
    "print(\"\\n--- Loading Data ---\")\n",
    "try:\n",
    "    loader = fast_openephys_dat_lfp(\n",
    "        filepath=dat_path,\n",
    "        num_channels=num_channels,\n",
    "        tetrode_groups={},\n",
    "        selected_channels=selected_channels,\n",
    "        sampling_frequency=fs_in,\n",
    "        target_sampling_frequency=fs_out,\n",
    "        return_mode=\"loader\",\n",
    "    )\n",
    "    fs = float(loader.sampling_frequency)\n",
    "    t_lfp = loader.time_vector()\n",
    "    print(f\"✓ LFP duration: {loader.duration:.2f}s at {fs:.1f} Hz\")\n",
    "\n",
    "    # Load spike data\n",
    "    npy_path = r'D:\\Spikeinterface_practice\\s4_rec\\phyMS5'\n",
    "    save_path = r'D:\\Spikeinterface_practice\\s4_rec'\n",
    "    if not os.path.exists(os.path.join(save_path, 'units.npy')):\n",
    "        print(\"Processing spike data...\")\n",
    "        process_spike_data(npy_path, save_path, samp_freq=30000)\n",
    "\n",
    "    units_file = os.path.join(save_path, 'units.npy')\n",
    "    processed_spike_data = load_processed_spike_data(units_file)\n",
    "\n",
    "    spike_analysis = SpikeAnalysis(\n",
    "        processed_data=processed_spike_data,\n",
    "        sampling_rate=30000,\n",
    "        duration=loader.duration\n",
    "    )\n",
    "\n",
    "    region_mapping = {7: 'CA1', 8: 'CA1', 6: 'RTC', 2: 'PFC', 3: 'PFC'}\n",
    "    spike_analysis.assign_brain_regions(region_mapping)\n",
    "\n",
    "    mua_by_region = spike_analysis.compute_mua_all_regions(t_lfp=t_lfp, kernel_width=0.01)\n",
    "    mua_vec = mua_by_region['CA1']\n",
    "\n",
    "    region_channels = find_region_channels(list(loader.selected_channels.keys()))\n",
    "    region_lfp = build_region_lfp(loader, region_channels)\n",
    "    lfp_array = region_lfp['CA1']\n",
    "    \n",
    "    print(f\"✓ LFP shape: {lfp_array.shape}\")\n",
    "    print(f\"✓ MUA vector length: {len(mua_vec)}\")\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"\\nERROR: Data files not found: {e}\")\n",
    "    print(f\"Attempted to load LFP from: {dat_path}\")\n",
    "    print(\"Cannot proceed without data. Exiting.\")\n",
    "    return\n",
    "\n",
    "# --- SWR Detection ---\n",
    "print(\"\\n--- Detecting SWRs ---\")\n",
    "ripple_th = 2.75\n",
    "params = SWRHMMParams(\n",
    "    ripple_band=(125, 250),\n",
    "    threshold_multiplier=ripple_th,\n",
    "    use_smoothing=True,\n",
    "    smoothing_sigma=0.01,\n",
    "    normalization_method='zscore',\n",
    "    min_duration=0.025,\n",
    "    max_duration=0.4,\n",
    "    min_event_separation=0.07,\n",
    "    merge_interval=0.07,\n",
    "    trace_window=1.0,\n",
    "    adaptive_classification=True,\n",
    "    dbscan_eps=0.15,\n",
    "    mua_threshold_multiplier=2.5,\n",
    "    mua_min_duration=0.03,\n",
    "    enable_mua=True,\n",
    "    use_hmm_edge_detection=False,\n",
    "    hmm_margin=0.1,\n",
    "    use_global_hmm=False,\n",
    "    global_hmm_fraction=0.1,\n",
    "    hmm_states_ripple=2,\n",
    "    hmm_states_mua=2,\n",
    "    use_hysteresis=True,\n",
    "    hysteresis_low_multiplier=0.75,\n",
    "    hysteresis_confirmation_window=0.07\n",
    ")\n",
    "\n",
    "detector = SWRHMMDetector(\n",
    "    lfp_data=lfp_array,\n",
    "    fs=fs,\n",
    "    mua_data=mua_vec,\n",
    "    params=params\n",
    ")\n",
    "\n",
    "detector.detect_events(channels=[0], average_mode=False)\n",
    "detector.classify_events_improved()\n",
    "\n",
    "print(f\"✓ Found {len(detector.swr_events)} events\")\n",
    "\n",
    "# --- Compute Spectrograms ---\n",
    "print(\"\\n--- Computing Spectrograms ---\")\n",
    "for event in detector.swr_events:\n",
    "    event['spec_method'] = 'cwt'\n",
    "\n",
    "lfp_channel = region_lfp['CA1'][0]\n",
    "n_computed = batch_compute_spectral_features(\n",
    "    detector, \n",
    "    lfp_channel, \n",
    "    fs,\n",
    "    use_optimized_cwt=True,\n",
    "    n_workers=20,\n",
    "    verbose=True,\n",
    "    target_freq_bins=150,\n",
    "    n_bins=100,\n",
    "    smoothing_sigma=1.0,\n",
    "    pre_ms=250,\n",
    "    post_ms=250\n",
    ")\n",
    "print(f\"✓ Successfully computed {n_computed} spectrograms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Generate Spectrograms and Extract Features\n",
    "\n",
    "This step runs `generate_spectrograms.py`.\n",
    "- Detects SWR events from the raw data.\n",
    "- Generates spectrogram images for each event.\n",
    "- Extracts biological features (duration, frequency, power, etc.).\n",
    "\n",
    "**Output files (saved to recording_path):**\n",
    "- `all_spectrograms/` (directory)\n",
    "- `detected_events.pkl`\n",
    "- `biological_features.pkl`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 1: GENERATING SPECTROGRAMS AND FEATURES...\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "try:\n",
    "    # Imports from pfr_neurophys_data_analysis/cnn_autoencoder/generate_spectrograms.py\n",
    "    from cnn_autoencoder.generate_spectrograms import generate_spectrograms_and_features\n",
    "    \n",
    "    generate_spectrograms_and_features()\n",
    "    \n",
    "    print(\"\\n\" + \"-\"*80)\n",
    "    print(\"STEP 1 COMPLETE\")\n",
    "    print(\"-\"*80)\n",
    "except ImportError:\n",
    "    print(f\"ERROR: Could not import 'generate_spectrograms_and_features'.\")\n",
    "    print(f\"Ensure 'generate_spectrograms.py' is in {os.path.join(project_root, 'cnn_autoencoder')}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during Step 1: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Train Autoencoder\n",
    "\n",
    "This step runs `train_autoencoder.py`.\n",
    "- Loads the spectrograms from `all_spectrograms/`.\n",
    "- Trains the specified CNN autoencoder (`resnet` or `vae`).\n",
    "\n",
    "**Output files (saved to recording_path):**\n",
    "- `full_model_resnet.pkl` (or similar, based on arch)\n",
    "- `encoder_model_resnet.pkl`\n",
    "- `training_history_resnet.png`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 2: TRAINING AUTOENCODER...\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "try:\n",
    "    # Imports from pfr_neurophys_data_analysis/cnn_autoencoder/train_autoencoder.py\n",
    "    from cnn_autoencoder.train_autoencoder import train_autoencoder_improved\n",
    "    \n",
    "    train_autoencoder_improved(\n",
    "        arch=ARCH,\n",
    "        latent_dim=LATENT_DIM,\n",
    "        epochs=EPOCHS,\n",
    "        lr=None,      # Use 'None' to trigger auto learning rate finder\n",
    "        beta=1.0      # Beta parameter for VAE (ignored for ResNet)\n",
    "    )\n",
    "    \n",
    "    print(\"\\n\" + \"-\"*80)\n",
    "    print(\"STEP 2 COMPLETE\")\n",
    "    print(\"-\"*80)\n",
    "except ImportError:\n",
    "    print(f\"ERROR: Could not import 'train_autoencoder_improved'.\")\n",
    "    print(f\"Ensure 'train_autoencoder.py' is in {os.path.join(project_root, 'cnn_autoencoder')}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during Step 2: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Cluster Events\n",
    "\n",
    "This step runs `cluster_events.py`.\n",
    "- Loads the trained encoder (`encoder_model_...pkl`).\n",
    "- Loads the biological features (`biological_features.pkl`).\n",
    "- Generates latent features from the autoencoder.\n",
    "- Combines features and performs clustering to find optimal k.\n",
    "\n",
    "**Output files (saved to recording_path):**\n",
    "- `events_with_clusters_combined.pkl`\n",
    "- `clustering_info_combined.pkl`\n",
    "- `clustering_metrics_plot.png`\n",
    "- `dendrogram.png`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 3: CLUSTERING EVENTS...\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "try:\n",
    "    # Imports from pfr_neurophys_data_analysis/cnn_autoencoder/cluster_events.py\n",
    "    from cnn_autoencoder.cluster_events import cluster_events_improved\n",
    "    \n",
    "    cluster_events_improved(\n",
    "        arch=ARCH,\n",
    "        latent_dim=LATENT_DIM,\n",
    "        k_range=range(2, 13),  # Test k from 2 to 12\n",
    "        ae_weight=0.7,\n",
    "        bio_weight=0.3,\n",
    "        use_combined_features=True\n",
    "    )\n",
    "    \n",
    "    print(\"\\n\" + \"-\"*80)\n",
    "    print(\"STEP 3 COMPLETE\")\n",
    "    print(\"-\"*80)\n",
    "except ImportError:\n",
    "    print(f\"ERROR: Could not import 'cluster_events_improved'.\")\n",
    "    print(f\"Ensure 'cluster_events.py' is in {os.path.join(project_root, 'cnn_autoencoder')}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during Step 3: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Evaluate and Validate Clusters\n",
    "\n",
    "This step runs `evaluate_clusters.py`.\n",
    "- Loads the clustered events (`events_with_clusters_combined.pkl`).\n",
    "- Performs detailed biological validation.\n",
    "- Generates summary plots and visualizations.\n",
    "\n",
    "**Output files (saved to recording_path):**\n",
    "- `feature_space_combined.png`\n",
    "- `cluster_validation_report_combined.txt`\n",
    "- `cluster_..._summary.png` (and other plots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 4: EVALUATING CLUSTERS...\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "try:\n",
    "    # Imports from pfr_neurophys_data_analysis/cnn_autoencoder/evaluate_clusters.py\n",
    "    from cnn_autoencoder.evaluate_clusters import evaluate_clusters_improved\n",
    "    \n",
    "    # Use 'combined' since we clustered with combined features in Step 3\n",
    "    evaluate_clusters_improved(feature_type='combined')\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"PIPELINE FINISHED!\")\n",
    "    print(f\"All outputs saved to: {os.getcwd()}\")\n",
    "    print(\"=\"*80)\n",
    "except ImportError:\n",
    "    print(f\"ERROR: Could not import 'evaluate_clusters_improved'.\")\n",
    "    print(f\"Ensure 'evaluate_clusters.py' is in {os.path.join(project_root, 'cnn_autoencoder')}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during Step 4: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
